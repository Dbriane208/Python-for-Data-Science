{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "727f69a9",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "- <b>This notebook provides a sample guideline on how you can prepare your raw data from various data sources for Machine Learining and Data analysis.The notebook is more focused on the data preprocessing process. </b>\n",
    "\n",
    "<b>\n",
    " NOTE :\n",
    "- The whole process may not apply to all datasets so its advisable to use your domain expertise to apply the necessary techniques on your datasets to get the desired results. </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58fadac2",
   "metadata": {},
   "source": [
    "# The Data Science workflow\n",
    "\n",
    "- <b>The data science workflow consists of six major steps which are not linear. This means that depending on your task you will need to go back and forth through this process. </b>\n",
    "- <b>The six steps include:\n",
    "   - Scoping a project\n",
    "   - Gathering Data\n",
    "   - Cleaning Data\n",
    "   - Exploring Data\n",
    "   - Modeling Data\n",
    "   - Sharing Insights </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "947ebc19",
   "metadata": {},
   "source": [
    "# 1. Scoping a project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c1846a5",
   "metadata": {},
   "source": [
    "- <b>It involves clearly defining your objectives you need to achieve given certain datasets. Some of these objectives may include :\n",
    "    - Who are your end users or stakeholders?\n",
    "    - What business problems are you trying to solve?\n",
    "    - Which Machine Learning algorithms are you going to use? </b>\n",
    "- <b>Scoping steps include :\n",
    "    - Think like an end user\n",
    "    - Brainstorm problems and solutions\n",
    "    - Identify data requirements and techniques </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76df95d1",
   "metadata": {},
   "source": [
    "# 2. Gathering Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f978da4b",
   "metadata": {},
   "source": [
    " - <b> Gathering the right data is essential to set a proper foundation for your analysis. </b>\n",
    " - <b>This process involves :\n",
    "    - Finding the data from data sources eg Local files, Databases, Web access etc\n",
    "    - Reading it into python\n",
    "    - Transforming it if necessary\n",
    "    - Storing the data into Pandas DataFrame </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c2a1e97",
   "metadata": {},
   "source": [
    "#### Reading files into python using different file formats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef00ec6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the Pandas library\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf97b201",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>ap_hi</th>\n",
       "      <th>ap_lo</th>\n",
       "      <th>cholesterol</th>\n",
       "      <th>smoke</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>18393</td>\n",
       "      <td>2</td>\n",
       "      <td>168</td>\n",
       "      <td>62.0</td>\n",
       "      <td>110</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>20228</td>\n",
       "      <td>1</td>\n",
       "      <td>156</td>\n",
       "      <td>85.0</td>\n",
       "      <td>140</td>\n",
       "      <td>90</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>18857</td>\n",
       "      <td>1</td>\n",
       "      <td>165</td>\n",
       "      <td>64.0</td>\n",
       "      <td>130</td>\n",
       "      <td>70</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id    age  gender  height  weight  ap_hi  ap_lo  cholesterol  smoke\n",
       "0   0  18393       2     168    62.0    110     80            1      0\n",
       "1   1  20228       1     156    85.0    140     90            3      0\n",
       "2   2  18857       1     165    64.0    130     70            3      0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading csv formats\n",
    "df_csv = pd.read_csv(\"../Data/cardio_base.csv\")\n",
    "df_csv.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ecfbe99c",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Data/Groceries.xlsx'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Reading excel formats\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m df_excel \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_excel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mData/Groceries.xlsx\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m df_excel\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m3\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/util/_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[0;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/util/_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    330\u001b[0m     )\n\u001b[0;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/io/excel/_base.py:482\u001b[0m, in \u001b[0;36mread_excel\u001b[0;34m(io, sheet_name, header, names, index_col, usecols, squeeze, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, thousands, decimal, comment, skipfooter, convert_float, mangle_dupe_cols, storage_options)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(io, ExcelFile):\n\u001b[1;32m    481\u001b[0m     should_close \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 482\u001b[0m     io \u001b[38;5;241m=\u001b[39m \u001b[43mExcelFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mio\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    483\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m engine \u001b[38;5;129;01mand\u001b[39;00m engine \u001b[38;5;241m!=\u001b[39m io\u001b[38;5;241m.\u001b[39mengine:\n\u001b[1;32m    484\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    485\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEngine should not be specified when passing \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    486\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124man ExcelFile - ExcelFile already has the engine set\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    487\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/io/excel/_base.py:1652\u001b[0m, in \u001b[0;36mExcelFile.__init__\u001b[0;34m(self, path_or_buffer, engine, storage_options)\u001b[0m\n\u001b[1;32m   1650\u001b[0m     ext \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxls\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1651\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1652\u001b[0m     ext \u001b[38;5;241m=\u001b[39m \u001b[43minspect_excel_format\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1653\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontent_or_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\n\u001b[1;32m   1654\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1655\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ext \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1656\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1657\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExcel file format cannot be determined, you must specify \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1658\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124man engine manually.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1659\u001b[0m         )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/io/excel/_base.py:1525\u001b[0m, in \u001b[0;36minspect_excel_format\u001b[0;34m(content_or_path, storage_options)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(content_or_path, \u001b[38;5;28mbytes\u001b[39m):\n\u001b[1;32m   1523\u001b[0m     content_or_path \u001b[38;5;241m=\u001b[39m BytesIO(content_or_path)\n\u001b[0;32m-> 1525\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1526\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcontent_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[1;32m   1527\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handle:\n\u001b[1;32m   1528\u001b[0m     stream \u001b[38;5;241m=\u001b[39m handle\u001b[38;5;241m.\u001b[39mhandle\n\u001b[1;32m   1529\u001b[0m     stream\u001b[38;5;241m.\u001b[39mseek(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/io/common.py:865\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    856\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[1;32m    857\u001b[0m             handle,\n\u001b[1;32m    858\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    861\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    862\u001b[0m         )\n\u001b[1;32m    863\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    864\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m--> 865\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    866\u001b[0m     handles\u001b[38;5;241m.\u001b[39mappend(handle)\n\u001b[1;32m    868\u001b[0m \u001b[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Data/Groceries.xlsx'"
     ]
    }
   ],
   "source": [
    "# Reading excel formats\n",
    "df_excel = pd.read_excel(\"../Data/Groceries.xlsx\")\n",
    "df_excel.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1033866c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading data from the database\n",
    "\n",
    "# Importing the database connector\n",
    "import sqlite3\n",
    "\n",
    "# Connect to the database\n",
    "connect = sqlite3.connect('../Data/maven.db')\n",
    "\n",
    "# We can read the data using pandas\n",
    "df_sql = pd.read_sql('select * from courses',connect)\n",
    "df_sql.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "701dd029",
   "metadata": {},
   "source": [
    "#### Exploring a DataFrame\n",
    "- This helps to ensure that the data was imported correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c8a01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# head - displays the first rows of a DataFrame\n",
    "# We can also pass an argument of how many rows we want to see as we did above\n",
    "\n",
    "df_csv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e011f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shape - displays the number of rows and columns in a dataFrame\n",
    "# Groceries have 25 rows and 7 columns\n",
    "\n",
    "df_excel.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06cd4af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# count - displays the number of values in each column\n",
    "# we have a total of 5 courses in our database\n",
    "\n",
    "df_sql.course.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd48fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# describe - displays summary statistics like mean, min and max\n",
    "# The mean,min and max of the height column in our csv data is 164..., 55,250\n",
    "\n",
    "df_csv.height.mean() , df_csv.height.min() , df_csv.height.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474f149a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# info - displays the non-null values and data types of each column\n",
    "df_csv.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb418ffc",
   "metadata": {},
   "source": [
    "# 3. Cleaning the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce4b740c",
   "metadata": {},
   "source": [
    "- Cleaning the data involves converting columns to the correct data types, handling data issues and creating new columns for analysis.\n",
    "- Common data issues include :\n",
    "    - Duplicates\n",
    "    - Outliers\n",
    "    - Missing Data\n",
    "    - Inconsistent text & typos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db37bb79",
   "metadata": {},
   "source": [
    "### a) converting columns into the correct type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c07029",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we use .dtypes to check the data types of each column in a dataset\n",
    "df_csv.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcdd45e8",
   "metadata": {},
   "source": [
    "- When converting object columns to numeric columns we use pd.to_numeric()\n",
    "- When converting object columns to datetime columns we use pd.to_datetime()\n",
    "- To change the date format we use pd.to_datetime(dt_col,format ='%Y-%M-%D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "230949b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# When converting object columns to numeric columns we use pd.to_numeric()\n",
    "data_runtime = pd.read_excel(\"../Data/Run Times.xlsx\")\n",
    "data_runtime.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18265d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking the dtypes\n",
    "data_runtime.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33351ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting the Warm Up Time column to numeric from object\n",
    "# To achieve this we must ensure that the column contains data of the same type \n",
    "# the purpose of this code was to remove min string from the values in the Warm Up Time column\n",
    "\n",
    "data_runtime['Warm Up Time'] = data_runtime['Warm Up Time'].astype('str').str.replace(' min','')\n",
    "data_runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01cb91a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting the Warm Up Time column to numeric from object\n",
    "# now the data type of the warm up column has changed from object to a float\n",
    "\n",
    "data_runtime['Warm Up Time'] = pd.to_numeric(data_runtime['Warm Up Time'])\n",
    "data_runtime.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b2863a6",
   "metadata": {},
   "source": [
    "### b) Identifying and handling missing data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6386d8bc",
   "metadata": {},
   "source": [
    "- The easiest way to identify missing data is with the <b>.isna()</b> method.\n",
    "- You can also use <b>.info()</b> or <b>the .value_counts().</b>\n",
    "- You can handle missing data by either mean,mode or median or fill them using 0 or droping the rows and columns with missing data.\n",
    "- <b>Note</b> : The best way to fill the missing values is by using your domain expertise knowledge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b46336",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for missing data using the isna() which returns true if any and false is not\n",
    "data_runtime.isna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1eccc97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking another dataset using the isna.sum() which returns the total missing values - no missing values\n",
    "df_csv.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bae8dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using .info() to check on the missing values - no missing values\n",
    "df_excel.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "024195ff",
   "metadata": {},
   "source": [
    "- The <b>.dropna()</b> method is used to remove rows with missing data.\n",
    "- After removing some data we reset the rows using the <b>.reset_index()</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "128a5d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading a dataset that has missing values\n",
    "students = pd.read_excel(\"../Data/Student Grades.xlsx\")\n",
    "students.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3eeb0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking for the missing values so that we can work on them\n",
    "students.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2742ae03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's fill the Grade with the mean\n",
    "# If you run the cell above you will find that Grade column has missing values\n",
    "\n",
    "students.Grade = students.Grade.fillna(students.Grade.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0fcec38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's fill the missing year by imputing senior using the numpy where method\n",
    "import numpy as np\n",
    "\n",
    "students.Year = np.where(students.Year.isna(),'Senior',students.Year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef71f010",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets drop the remaining missing values using the dropna method\n",
    "# We're using the .values to extract the first no-missing values\n",
    "\n",
    "students.Student = students.Student.fillna(students.Student.dropna().values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dfe7065",
   "metadata": {},
   "outputs": [],
   "source": [
    "students.Class = students.Class.fillna(students.Class.dropna().values[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33bd66a5",
   "metadata": {},
   "source": [
    "### c) Identifying and handling duplicated values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "985f6886",
   "metadata": {},
   "source": [
    "- We identify duplicated data by using <b>.duplicated</b> method which returns false for no duplicates and true for duplicates.\n",
    "- We remove duplicates by using the <b>drop_duplicated<> method."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2197d212",
   "metadata": {},
   "source": [
    "### d) Outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "864159b0",
   "metadata": {},
   "source": [
    "- Outliers are values in a dataset that are much bigger or smaller than others.\n",
    "- Outliers are identified by using plots and statistics ie histogram,box plot,standard deviation\n",
    "- Outliers are handled by either keeping them,removing the rows and columns where they exist or imputing them with NaN values or by resolving them using your domain experitise."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c81135c0",
   "metadata": {},
   "source": [
    "#### Histogram\n",
    "- It help to identify outliers by showing which values fall outside of the normal range\n",
    "- We use seaborn library to visualize the plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "341542b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing seaborn library\n",
    "import seaborn as sns\n",
    "\n",
    "# plotting the histogram\n",
    "# From the histogram we have four outliers\n",
    "sns.histplot(students);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d07945",
   "metadata": {},
   "source": [
    "#### Boxplot\n",
    "- They automatically plot outliers as dots outside of the min/max data range.\n",
    "- The width of the box is the <b>interquartile range(IQR)</b>, which is the middle 50% of the data.\n",
    "- Any value farther away than (1.5 * IQR) from each side of the box is considered an outlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec90c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ploting a boxplot\n",
    "# shows the four outliers we have\n",
    "\n",
    "sns.boxplot(x=students.Grade);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5717570b",
   "metadata": {},
   "source": [
    "#### Standard deviation\n",
    "- It is the measure of the spread of a dataset from the mean.\n",
    "- Values at least 3 standard deviations away from the mean are considered outliers. This is meant for normaly distributed data.\n",
    "- The threshold of 3 standard deviations can be changed to 2 or 4 depending on the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2e17c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the mean and the std\n",
    "mean = np.mean(students.Grade)\n",
    "std =  np.std(students.Grade)\n",
    "\n",
    "mean, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0220468",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returning the outliers\n",
    "[grade for grade in students.Grade \n",
    " if (grade < mean - 2*std) or \n",
    " (grade > mean + 2*std)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b711d74",
   "metadata": {},
   "source": [
    "# 4. Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab0a05a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
